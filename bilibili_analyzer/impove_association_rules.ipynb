{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10339\n",
      "<class 'generator'>\n",
      "-------------挖掘频繁项集---------------\n",
      "                fluent_patterns   support\n",
      "0                      [102392]  0.315795\n",
      "1                        [8892]  0.269272\n",
      "2                [102392, 8892]  0.142083\n",
      "3                [139252, 8892]  0.141213\n",
      "4        [102392, 139252, 8892]  0.086952\n",
      "5               [5267730, 8892]  0.144405\n",
      "6       [102392, 5267730, 8892]  0.086179\n",
      "7       [139252, 5267730, 8892]  0.103008\n",
      "8                     [4312482]  0.205726\n",
      "9             [102392, 4312482]  0.099139\n",
      "10              [8892, 4312482]  0.103105\n",
      "11      [139252, 8892, 4312482]  0.075249\n",
      "12     [5267730, 8892, 4312482]  0.075152\n",
      "13            [139252, 4312482]  0.123803\n",
      "14           [5267730, 4312482]  0.120708\n",
      "15   [139252, 5267730, 4312482]  0.091208\n",
      "16            [130412, 4312482]  0.097011\n",
      "17    [139252, 130412, 4312482]  0.076700\n",
      "18   [5267730, 130412, 4312482]  0.072831\n",
      "19                     [135652]  0.194893\n",
      "20             [102392, 135652]  0.088306\n",
      "21               [8892, 135652]  0.088016\n",
      "22            [4312482, 135652]  0.088306\n",
      "23             [139252, 135652]  0.102911\n",
      "24            [5267730, 135652]  0.099913\n",
      "25    [139252, 5267730, 135652]  0.072638\n",
      "26             [130412, 135652]  0.084631\n",
      "27                    [4316382]  0.188510\n",
      "28            [102392, 4316382]  0.097688\n",
      "29              [8892, 4316382]  0.106780\n",
      "..                          ...       ...\n",
      "416                      [5989]  0.080569\n",
      "417                      [1539]  0.077087\n",
      "418                     [17632]  0.076410\n",
      "419                      [8812]  0.120418\n",
      "420                [8892, 8812]  0.071961\n",
      "421              [102392, 8812]  0.073218\n",
      "422                      [5069]  0.089177\n",
      "423                     [23432]  0.077957\n",
      "424                     [97912]  0.071477\n",
      "425                      [5793]  0.115001\n",
      "426                      [1733]  0.110359\n",
      "427                       [184]  0.094980\n",
      "428                      [7452]  0.128929\n",
      "429               [78552, 7452]  0.079602\n",
      "430                      [2572]  0.090047\n",
      "431                       [963]  0.082987\n",
      "432                      [5800]  0.188896\n",
      "433              [102392, 5800]  0.106297\n",
      "434              [139252, 5800]  0.085598\n",
      "435             [5267730, 5800]  0.085598\n",
      "436                [8892, 5800]  0.085501\n",
      "437                [5997, 5800]  0.107554\n",
      "438                [3450, 5800]  0.073798\n",
      "439                [3461, 5800]  0.082503\n",
      "440                      [6001]  0.096431\n",
      "441                      [2580]  0.133088\n",
      "442              [102392, 2580]  0.075056\n",
      "443                      [4188]  0.080085\n",
      "444                      [5070]  0.074765\n",
      "445                      [1650]  0.085018\n",
      "\n",
      "[446 rows x 2 columns]\n",
      "                         rules_a           rules_b  confidence\n",
      "0     (139252, 4316482, 4316382)         (5267730)    0.899207\n",
      "1             (5267750, 4316382)         (5267730)    0.898389\n",
      "2             (4762754, 4316382)         (5267730)    0.893303\n",
      "3        (139252, 8892, 4316382)         (5267730)    0.885057\n",
      "4     (130412, 4316482, 5267730)          (139252)    0.878021\n",
      "5             (4312482, 4316382)         (5267730)    0.872222\n",
      "6      (139252, 130412, 4316382)         (5267730)    0.872043\n",
      "7             (4316482, 4316382)         (5267730)    0.871673\n",
      "8    (5267730, 4316482, 4316382)          (139252)    0.865867\n",
      "9              (134912, 4316382)         (5267730)    0.861111\n",
      "10             (134912, 4316482)          (139252)    0.859954\n",
      "11             (139252, 4316442)         (5267730)    0.856187\n",
      "12             (102252, 4316482)          (139252)    0.855803\n",
      "13               (8892, 4316382)         (5267730)    0.854167\n",
      "14             (134932, 4316382)         (5267730)    0.853922\n",
      "15             (139252, 4316382)         (5267730)    0.852015\n",
      "16                        (1587)            (1586)    0.851810\n",
      "17             (130412, 4316382)         (5267730)    0.850442\n",
      "18    (130412, 5267730, 4316382)          (139252)    0.843913\n",
      "19             (139252, 4762754)         (5267730)    0.841991\n",
      "20            (4316482, 4316382)          (139252)    0.839354\n",
      "21             (130412, 4316482)          (139252)    0.839080\n",
      "22             (102392, 4316382)         (5267730)    0.833663\n",
      "23               (4316482, 8892)          (139252)    0.833503\n",
      "24            (5267730, 4316482)          (139252)    0.830818\n",
      "25            (4762754, 4316382)          (139252)    0.826334\n",
      "26       (130412, 8892, 5267730)          (139252)    0.825556\n",
      "27             (102392, 4316482)          (139252)    0.824462\n",
      "28            (5267730, 4762754)         (4316382)    0.823222\n",
      "29             (102252, 5267730)          (139252)    0.823171\n",
      "..                           ...               ...         ...\n",
      "232               (102392, 5997)         (5267730)    0.614686\n",
      "233           (5267730, 4316482)         (4312482)    0.613979\n",
      "234                     (139252)         (5267730)    0.613882\n",
      "235                       (8752)            (8892)    0.613048\n",
      "236               (102392, 8892)          (139252)    0.611981\n",
      "237            (5267730, 102392)            (8892)    0.611531\n",
      "238                    (4762734)         (5267730)    0.611004\n",
      "239             (102792, 102392)         (5267730)    0.609715\n",
      "240                    (5267750)         (4312482)    0.609058\n",
      "241           (5267730, 4316382)            (8892)    0.608780\n",
      "242             (130412, 134912)         (4316382)    0.608514\n",
      "243                       (8812)          (102392)    0.608032\n",
      "244             (139252, 130412)         (4316382)    0.607843\n",
      "245            (139252, 4312482)            (8892)    0.607812\n",
      "246           (5267730, 4316482)            (8892)    0.607625\n",
      "247                   (24097891)         (5267730)    0.607020\n",
      "248                     (134912)         (5267730)    0.606968\n",
      "249           (4312482, 5267730)         (5267750)    0.606571\n",
      "250               (102392, 8892)         (5267730)    0.606535\n",
      "251                   (22503880)        (22718131)    0.606184\n",
      "252           (5267730, 4316482)  (139252, 130412)    0.606037\n",
      "253            (139252, 5267730)            (8892)    0.605114\n",
      "254                       (1586)            (1587)    0.604819\n",
      "255               (102252, 8792)          (102392)    0.604459\n",
      "256                       (8772)            (6301)    0.604183\n",
      "257           (4312482, 5267730)          (130412)    0.603365\n",
      "258             (139252, 102392)            (8892)    0.603356\n",
      "259              (5267730, 8892)          (130412)    0.602813\n",
      "260                      (78352)          (102392)    0.602158\n",
      "261                    (4312482)          (139252)    0.601787\n",
      "\n",
      "[262 rows x 3 columns]\n",
      "                         rules_a     rules_b  confidence\n",
      "0     (139252, 4316482, 4316382)   (5267730)    0.899207\n",
      "1             (5267750, 4316382)   (5267730)    0.898389\n",
      "2             (4762754, 4316382)   (5267730)    0.893303\n",
      "3        (139252, 8892, 4316382)   (5267730)    0.885057\n",
      "4     (130412, 4316482, 5267730)    (139252)    0.878021\n",
      "5             (4312482, 4316382)   (5267730)    0.872222\n",
      "6      (139252, 130412, 4316382)   (5267730)    0.872043\n",
      "7             (4316482, 4316382)   (5267730)    0.871673\n",
      "8    (5267730, 4316482, 4316382)    (139252)    0.865867\n",
      "9              (134912, 4316382)   (5267730)    0.861111\n",
      "10             (134912, 4316482)    (139252)    0.859954\n",
      "11             (139252, 4316442)   (5267730)    0.856187\n",
      "12             (102252, 4316482)    (139252)    0.855803\n",
      "13               (8892, 4316382)   (5267730)    0.854167\n",
      "14             (134932, 4316382)   (5267730)    0.853922\n",
      "15             (139252, 4316382)   (5267730)    0.852015\n",
      "16                        (1587)      (1586)    0.851810\n",
      "17             (130412, 4316382)   (5267730)    0.850442\n",
      "18    (130412, 5267730, 4316382)    (139252)    0.843913\n",
      "19             (139252, 4762754)   (5267730)    0.841991\n",
      "20            (4316482, 4316382)    (139252)    0.839354\n",
      "21             (130412, 4316482)    (139252)    0.839080\n",
      "22             (102392, 4316382)   (5267730)    0.833663\n",
      "23               (4316482, 8892)    (139252)    0.833503\n",
      "24            (5267730, 4316482)    (139252)    0.830818\n",
      "25            (4762754, 4316382)    (139252)    0.826334\n",
      "26       (130412, 8892, 5267730)    (139252)    0.825556\n",
      "27             (102392, 4316482)    (139252)    0.824462\n",
      "28            (5267730, 4762754)   (4316382)    0.823222\n",
      "29             (102252, 5267730)    (139252)    0.823171\n",
      "..                           ...         ...         ...\n",
      "239           (5267730, 4316482)   (4312482)    0.613979\n",
      "240                     (139252)   (5267730)    0.613882\n",
      "241                       (8752)      (8892)    0.613048\n",
      "242               (102392, 8892)    (139252)    0.611981\n",
      "243            (5267730, 102392)      (8892)    0.611531\n",
      "244                    (4762734)   (5267730)    0.611004\n",
      "245             (102792, 102392)   (5267730)    0.609715\n",
      "246                    (5267750)   (4312482)    0.609058\n",
      "247           (5267730, 4316382)      (8892)    0.608780\n",
      "248             (130412, 134912)   (4316382)    0.608514\n",
      "249                       (8812)    (102392)    0.608032\n",
      "250             (139252, 130412)   (4316382)    0.607843\n",
      "251            (139252, 4312482)      (8892)    0.607812\n",
      "252           (5267730, 4316482)      (8892)    0.607625\n",
      "253                   (24097891)   (5267730)    0.607020\n",
      "254                     (134912)   (5267730)    0.606968\n",
      "255           (4312482, 5267730)   (5267750)    0.606571\n",
      "256               (102392, 8892)   (5267730)    0.606535\n",
      "257                   (22503880)  (22718131)    0.606184\n",
      "258           (5267730, 4316482)      139252    0.606037\n",
      "259           (5267730, 4316482)      130412    0.606037\n",
      "260            (139252, 5267730)      (8892)    0.605114\n",
      "261                       (1586)      (1587)    0.604819\n",
      "262               (102252, 8792)    (102392)    0.604459\n",
      "263                       (8772)      (6301)    0.604183\n",
      "264           (4312482, 5267730)    (130412)    0.603365\n",
      "265             (139252, 102392)      (8892)    0.603356\n",
      "266              (5267730, 8892)    (130412)    0.602813\n",
      "267                      (78352)    (102392)    0.602158\n",
      "268                    (4312482)    (139252)    0.601787\n",
      "\n",
      "[269 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pyfpgrowth\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import fp_growth_py3 as fpg\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "filepath='./test_data/user_following_animation.json'\n",
    "data=pd.read_json(filepath,lines=True)\n",
    "data_list = list(data[\"value\"].dropna())\n",
    "print(len(data_list))\n",
    "\n",
    "def generate_frequent_items(minimum_support) :\n",
    "    frequent_itemsets = fpg.find_frequent_itemsets(data_list, minimum_support=0.07 * len(data_list), include_support=True)\n",
    "    print(type(frequent_itemsets))  # print type\n",
    "    result = []\n",
    "    for itemset, support in frequent_itemsets:  # 将generator结果存入list\n",
    "        result.append((itemset, support / len(data_list)))\n",
    "\n",
    "    result_patterns = [i[0] for i in result]\n",
    "    result_support = [i[1] for i in result]\n",
    "    patterns_df = pd.DataFrame({\"fluent_patterns\": result_patterns, \"support\": result_support})\n",
    "    patterns = {}\n",
    "    for i in result:\n",
    "        patterns[frozenset(sorted(i[0]))] = i[1]\n",
    "    print(\"-------------挖掘频繁项集---------------\")\n",
    "    print(patterns_df)\n",
    "\n",
    "    return patterns\n",
    "\n",
    "\n",
    "def generate_rules(patterns, min_confidence):\n",
    "    patterns_group = group_patterns_by_length(patterns)\n",
    "    raw_rules = defaultdict(set)\n",
    "    for length, pattern_list in patterns_group.items():\n",
    "        if length == 1:\n",
    "            continue\n",
    "        for pattern, support in pattern_list:\n",
    "            item_list = list(pattern)\n",
    "            for window_size in range(1, length):\n",
    "                for i in range(0, length - window_size):\n",
    "                    for j in range(i + window_size, length):\n",
    "                        base_set = frozenset(item_list[i:j])\n",
    "                        predict_set = frozenset(pattern - base_set)\n",
    "                        confidence = support / patterns.get(base_set)\n",
    "                        if confidence > min_confidence:\n",
    "                            raw_rules[base_set].add((predict_set, confidence))\n",
    "\n",
    "                        base_set, predict_set = predict_set, base_set\n",
    "                        confidence = support / patterns.get(base_set)\n",
    "                        if confidence > min_confidence:\n",
    "                            raw_rules[base_set].add((predict_set, confidence))\n",
    "    return raw_rules\n",
    "\n",
    "def group_patterns_by_length(patterns):\n",
    "    result = defaultdict(list)\n",
    "    for pattern, support in patterns.items():\n",
    "        result[len(pattern)].append((pattern, support))\n",
    "    return result\n",
    "\n",
    "def transform(raw_rules):\n",
    "    result = list()\n",
    "    for base_set, predict_set_list in raw_rules.items():\n",
    "        for predict_set, confidence in predict_set_list:\n",
    "            result.append((base_set, predict_set, confidence))\n",
    "\n",
    "    return result\n",
    "\n",
    "def transform_rules_to_df(raw_rules) :\n",
    "    rules = transform(raw_rules)\n",
    "    rules.sort(key=lambda x: x[2], reverse=True)\n",
    "    rules_a = [i[0] for i in rules]\n",
    "    rules_b = [i[1] for i in rules]\n",
    "    confidence = [i[2] for i in rules]\n",
    "    rules_df = pd.DataFrame({\"rules_a\": rules_a, \"rules_b\": rules_b, \"confidence\": confidence})\n",
    "    print(rules_df)\n",
    "    return rules_df\n",
    "\n",
    "def unfold_rules(rules_df) :\n",
    "    rules_df_temp = pd.DataFrame(columns=[\"rules_a\",\"rules_b\",\"confidence\"])\n",
    "    for index, row in rules_df.iterrows():\n",
    "        \n",
    "        if len(row[\"rules_b\"]) >1 :\n",
    "            rules_a = row[\"rules_a\"]\n",
    "            rules_b = row[\"rules_b\"]\n",
    "            confidence = row[\"confidence\"]\n",
    "            for i in rules_b :\n",
    "                rules_df_temp = rules_df_temp.append({\"rules_a\":rules_a, \"rules_b\":i, \"confidence\":confidence}, ignore_index=True)\n",
    "        else :\n",
    "            rules_df_temp = rules_df_temp.append({\"rules_a\":row[\"rules_a\"], \"rules_b\":row[\"rules_b\"], \"confidence\":row[\"confidence\"]}, ignore_index=True)\n",
    "    return rules_df_temp\n",
    "\n",
    "\n",
    "def count_repeat(rules_df):\n",
    "    count = 0\n",
    "    for index,row in rules_df.iterrows() :\n",
    "        if len(row[\"rules_b\"]) > 1:\n",
    "            count +=1\n",
    "    print(count)\n",
    "\n",
    "minimum_support = 0.07\n",
    "minimum_confidence = 0.6\n",
    "patterns = generate_frequent_items(minimum_support)\n",
    "raw_rules = generate_rules(patterns, minimum_confidence)\n",
    "\n",
    "rules_df = transform_rules_to_df(raw_rules)\n",
    "rules_df.to_csv(\"rules.csv\", index=False, header=False)\n",
    "\n",
    "rules_df = unfold_rules(rules_df)\n",
    "rules_df.to_csv(\"unfold_rules.csv\", index=False, header=False)\n",
    "\n",
    "print(rules_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         rules_a     rules_b  confidence     score\n",
      "0     (139252, 4316482, 4316382)   (5267730)    0.899207  1.550524\n",
      "1             (5267750, 4316382)   (5267730)    0.898389  1.550115\n",
      "2             (4762754, 4316382)   (5267730)    0.893303  1.547572\n",
      "3        (139252, 8892, 4316382)   (5267730)    0.885057  1.543449\n",
      "4     (130412, 4316482, 5267730)    (139252)    0.878021  1.555975\n",
      "5             (4312482, 4316382)   (5267730)    0.872222  1.537032\n",
      "6      (139252, 130412, 4316382)   (5267730)    0.872043  1.536942\n",
      "7             (4316482, 4316382)   (5267730)    0.871673  1.536757\n",
      "8    (5267730, 4316482, 4316382)    (139252)    0.865867  1.549898\n",
      "9              (134912, 4316382)   (5267730)    0.861111  1.531476\n",
      "10             (134912, 4316482)    (139252)    0.859954  1.546941\n",
      "11             (139252, 4316442)   (5267730)    0.856187  1.529014\n",
      "12             (102252, 4316482)    (139252)    0.855803  1.544866\n",
      "13               (8892, 4316382)   (5267730)    0.854167  1.528004\n",
      "14             (134932, 4316382)   (5267730)    0.853922  1.527881\n",
      "15             (139252, 4316382)   (5267730)    0.852015  1.526928\n",
      "16                        (1587)      (1586)    0.851810  1.619166\n",
      "17             (130412, 4316382)   (5267730)    0.850442  1.526142\n",
      "18    (130412, 5267730, 4316382)    (139252)    0.843913  1.538921\n",
      "19             (139252, 4762754)   (5267730)    0.841991  1.521916\n",
      "20            (4316482, 4316382)    (139252)    0.839354  1.536641\n",
      "21             (130412, 4316482)    (139252)    0.839080  1.536505\n",
      "22             (102392, 4316382)   (5267730)    0.833663  1.517752\n",
      "23               (4316482, 8892)    (139252)    0.833503  1.533716\n",
      "24            (5267730, 4316482)    (139252)    0.830818  1.532374\n",
      "25            (4762754, 4316382)    (139252)    0.826334  1.530131\n",
      "26       (130412, 8892, 5267730)    (139252)    0.825556  1.529742\n",
      "27             (102392, 4316482)    (139252)    0.824462  1.529196\n",
      "28            (5267730, 4762754)   (4316382)    0.823222  1.364568\n",
      "29             (102252, 5267730)    (139252)    0.823171  1.528550\n",
      "..                           ...         ...         ...       ...\n",
      "239           (5267730, 4316482)   (4312482)    0.613979  1.373075\n",
      "240                     (139252)   (5267730)    0.613882  1.407862\n",
      "241                       (8752)      (8892)    0.613048  1.382662\n",
      "242               (102392, 8892)    (139252)    0.611981  1.422955\n",
      "243            (5267730, 102392)      (8892)    0.611531  1.381904\n",
      "244                    (4762734)   (5267730)    0.611004  1.406423\n",
      "245             (102792, 102392)   (5267730)    0.609715  1.405778\n",
      "246                    (5267750)   (4312482)    0.609058  1.370615\n",
      "247           (5267730, 4316382)      (8892)    0.608780  1.380528\n",
      "248             (130412, 134912)   (4316382)    0.608514  1.257215\n",
      "249                       (8812)    (102392)    0.608032  1.451794\n",
      "250             (139252, 130412)   (4316382)    0.607843  1.256879\n",
      "251            (139252, 4312482)      (8892)    0.607812  1.380045\n",
      "252           (5267730, 4316482)      (8892)    0.607625  1.379951\n",
      "253                   (24097891)   (5267730)    0.607020  1.404431\n",
      "254                     (134912)   (5267730)    0.606968  1.404405\n",
      "255           (4312482, 5267730)   (5267750)    0.606571  1.338915\n",
      "256               (102392, 8892)   (5267730)    0.606535  1.404188\n",
      "257                   (22503880)  (22718131)    0.606184  1.328366\n",
      "258           (5267730, 4316482)      139252    0.606037  1.419983\n",
      "259           (5267730, 4316482)      130412    0.606037  1.272632\n",
      "260            (139252, 5267730)      (8892)    0.605114  1.378695\n",
      "261                       (1586)      (1587)    0.604819  1.462259\n",
      "262               (102252, 8792)    (102392)    0.604459  1.450007\n",
      "263                       (8772)      (6301)    0.604183  0.951266\n",
      "264           (4312482, 5267730)    (130412)    0.603365  1.271297\n",
      "265             (139252, 102392)      (8892)    0.603356  1.377816\n",
      "266              (5267730, 8892)    (130412)    0.602813  1.271020\n",
      "267                      (78352)    (102392)    0.602158  1.448857\n",
      "268                    (4312482)    (139252)    0.601787  1.417858\n",
      "\n",
      "[269 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def trans(raw_num):\n",
    "    result = 1\n",
    "    raw_num = raw_num[:-3]\n",
    "    if raw_num.endswith(\"亿\"):\n",
    "        result = result * 10 ** 8\n",
    "        raw_num = raw_num[:-1]\n",
    "    elif raw_num.endswith(\"万\"):\n",
    "        result = result * 10 ** 4\n",
    "        raw_num = raw_num[:-1]\n",
    "    \n",
    "    try:\n",
    "        result = result * float(raw_num)\n",
    "    except:\n",
    "        result = 0\n",
    "\n",
    "    return int(result)\n",
    "\n",
    "\n",
    "def add_score(rules_df,rules_weight) :\n",
    "    rules_df['score'] = 0\n",
    "    \n",
    "    # 读取animation 和 animation_feature\n",
    "    animation = pd.read_json(\"./test_data/bilibili_crawler_animation.json\", encoding=\"utf-8\")\n",
    "    animation[[\"follow\",\"play\"]] = animation[[\"follow\",\"play\"]].applymap(trans)\n",
    "    animation_feature = pd.read_json(\"./test_data/bilibili_crawler_animation_feature.json\",dtype={\"character_voice_list\":str})\n",
    "    animation_feature[[\"tag_list\",\"character_voice_list\",\"character_staff_list\"]] = animation_feature[[\"tag_list\",\"character_voice_list\",\"character_staff_list\"]].applymap(json.loads)\n",
    "    \n",
    "    max_follow = animation[\"follow\"].max()\n",
    "    max_play = animation[\"play\"].max()\n",
    "    score_list = []\n",
    "    for index,row in rules_df.iterrows():\n",
    "        score = 0\n",
    "        rules_a = row[\"rules_a\"]\n",
    "        rules_a = set(rules_a)\n",
    "        temp = set()\n",
    "        for i in rules_a :\n",
    "            i = int(i)\n",
    "            temp.add(i)\n",
    "        \n",
    "        rules_a = temp\n",
    "        \n",
    "        rules_b = ''.join(row[\"rules_b\"])\n",
    "        rules_b = int(rules_b)\n",
    "        \n",
    "        #如果某条规则中的番剧不在animation里面，说明其已经失效\n",
    "        if rules_b not in list(animation[\"media_id\"]) :\n",
    "            continue\n",
    "            \n",
    "        # 计算confidence\n",
    "        score += row[\"confidence\"] * rules_weight[\"confidence\"]\n",
    "    \n",
    "        #计算评分\n",
    "        temp = list(animation[animation[\"media_id\"]==rules_b].score)\n",
    "        temp = temp[0]\n",
    "        score += temp * rules_weight[\"score\"]\n",
    "        \n",
    "        #计算播放量\n",
    "        temp = list(animation[animation[\"media_id\"]==rules_b].play)\n",
    "        temp = temp[0]\n",
    "        score += (temp / max_play) * rules_weight[\"play\"]\n",
    "        \n",
    "        #计算追番用户\n",
    "        temp = list(animation[animation[\"media_id\"]==rules_b].follow)\n",
    "        temp = temp[0]\n",
    "        score += (temp / max_follow) * rules_weight[\"follow\"]\n",
    "        \n",
    "        #计算声优\n",
    "        voice_dict = animation_feature[animation_feature[\"media_id\"]==rules_b].character_voice_list\n",
    "        voice_dict = list(voice_dict)\n",
    "        voice_dict = voice_dict[0]\n",
    "        set_b_voice = set(voice_dict.values())\n",
    "        set_a_voice = set()\n",
    "        for i in rules_a:\n",
    "            #如果某条规则中的番剧不在animation里面，说明其已经失效\n",
    "            if i not in animation_feature[\"media_id\"] :\n",
    "                continue\n",
    "            voice_dict = animation_feature[animation_feature[\"media_id\"]==i].character_voice_list\n",
    "            voice_dict = list(voice_dict)\n",
    "            voice_dict = voice_dict[0]\n",
    "            voice_dict = set(voice_dict.values())\n",
    "            set_a_voice.update(voice_dict)\n",
    "        set_a_b_voice = set_a_voice.intersection(set_b_voice)\n",
    "        voice_overlap_count = len(set_a_b_voice) / len(set_b_voice) * rules_weight[\"voice\"]\n",
    "        score += voice_overlap_count\n",
    "        \n",
    "        #计算staff\n",
    "        staff_dict = animation_feature[animation_feature[\"media_id\"]==rules_b].character_staff_list\n",
    "        staff_dict = list(staff_dict)\n",
    "        staff_dict = staff_dict[0]\n",
    "        set_b_staff = set(staff_dict.values())\n",
    "        set_a_staff = set()\n",
    "        for i in rules_a:\n",
    "            #如果某条规则中的番剧不在animation里面，说明其已经失效\n",
    "            if i not in animation_feature[\"media_id\"] :\n",
    "                continue\n",
    "            staff_dict = animation_feature[animation_feature[\"media_id\"]==i].character_staff_list\n",
    "            staff_dict = list(staff_dict)\n",
    "            staff_dict = staff_dict[0]\n",
    "            staff_dict = set(staff_dict.values())\n",
    "            set_a_staff.update(staff_dict)\n",
    "        set_a_b_staff = set_a_staff.intersection(set_b_staff)\n",
    "        staff_overlap_count = len(set_a_b_staff) / len(set_b_staff) * rules_weight[\"staff\"]\n",
    "        score +=  staff_overlap_count\n",
    "        \n",
    "        #该条关联规则的评分\n",
    "        score_list.append(score)\n",
    "    rules_df[\"score\"] = score_list\n",
    "rules_weight = {\"confidence\":0.5, \"score\":0.1, \"play\":0.1, \"follow\":0.1, \"voice\":0.1, \"staff\":0.1}\n",
    "add_score(rules_df,rules_weight)\n",
    "print(rules_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
