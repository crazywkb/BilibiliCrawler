{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需模块\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import fp_growth_py3 as fpg\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_association_rules(rules_to_evaluate,test_datas):\n",
    "    \"\"\"\n",
    "    Parameters：\n",
    "        rules_to_evaluate：要评估的关联规则（推荐规则） list((rule_a,rule_b))\n",
    "        test_datas：测试用的数据集 dataframe\n",
    "\n",
    "    Returns：\n",
    "        关联规则（推荐规则）在测试集上的平均准确率\n",
    "    \"\"\"\n",
    "    point_sum = 0\n",
    "    miss = 0\n",
    "    for rule_a,rule_b in rules_to_evaluate:\n",
    "        set_rule_a = set(rule_a)\n",
    "        set_rule_b = set(rule_b)  \n",
    "        \n",
    "        num_a = 0\n",
    "        num_b = 0\n",
    "        \n",
    "        for test_data in test_datas.value:\n",
    "            set_test_data = set(test_data)\n",
    "            if set_rule_a.issubset(set_test_data):\n",
    "                num_a += 1\n",
    "                if set_rule_b.issubset(set_test_data):\n",
    "                    num_b += 1\n",
    "        if num_a:\n",
    "            point_sum += num_b / num_a\n",
    "        else:\n",
    "            miss += 1\n",
    "#     print(miss,' rules miss')\n",
    "    return point_sum / len(rules_to_evaluate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入测试数据集\n",
    "filepath='./test_data/user_following_animation.json'\n",
    "data=pd.read_json(filepath,lines=True)\n",
    "user_info = pd.read_csv(\"test_data/bilibili_crawler_user_info.csv\",names = ['id','mid','name','sex','sign','the_rank','level','jointime','moral','silence','birthday','coins','fans_badge','role','title','desc','vip_type','vip_status'])\n",
    "\n",
    "user_info.drop(user_info[user_info.vip_type.isna() | user_info.the_rank.isna() | user_info.level.isna()].index.tolist(),inplace=True) # 将vip_type、the_rank、level有NaN的行去掉\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_rules={'the_rank':{10000:1,20000:2,25000:3,30000:4},'level':{'3':1,'4':2,'5':3,'6':4},'vip_type':{0:0,1:1,2:2}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db                                                       7\n",
      "key                                         finished_users\n",
      "size                                                507576\n",
      "ttl                                                     -1\n",
      "type                                                   set\n",
      "value    [330817737, 74775, 259640193, 24774761, 540994...\n",
      "Name: 4504, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for index,row in data.iterrows():\n",
    "    try:\n",
    "        int(row.key)\n",
    "    except:\n",
    "        print(row)\n",
    "        data.drop(index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_power(data,rules,user_info):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        data:用户收藏ID数据集\n",
    "        rules:权重规则\n",
    "        user_info:用户信息数据集\n",
    "    return:新数据集\n",
    "        \n",
    "    \"\"\"\n",
    "    new_data = pd.DataFrame(columns=data.columns)\n",
    "    for index,row in data.iterrows():\n",
    "        info = user_info[user_info.mid == int(row.key)]\n",
    "\n",
    "        if len(info):\n",
    "            the_power = rules['the_rank'][info.the_rank.values[0]] + rules['level'][info.level.values[0]] + rules['vip_type'][info.vip_type.values[0]]\n",
    "        else:  # len(info)==0 说明在user_info中没有这个用户的相关数据\n",
    "            the_power = 1\n",
    "#         print(the_power)\n",
    "        for i in range(the_power):\n",
    "            new_data = new_data.append(row,ignore_index=True)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data= user_power(data,add_rules,user_info)\n",
    "training_data = new_data.sample(n=None, frac=0.9, replace=False, weights=None, random_state=None, axis=None)\n",
    "evaluate_data = new_data.drop([x for x in training_data.index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "-------------挖掘频繁项集---------------\n",
      "               fluent_patterns   support\n",
      "0                       [8892]  0.305986\n",
      "1               [102392, 8892]  0.161106\n",
      "2                     [135652]  0.220884\n",
      "3               [8892, 135652]  0.105506\n",
      "4            [5267730, 135652]  0.117209\n",
      "5      [8892, 5267730, 135652]  0.074773\n",
      "6    [139252, 5267730, 135652]  0.085704\n",
      "7             [139252, 135652]  0.118383\n",
      "8       [8892, 139252, 135652]  0.071882\n",
      "9             [130412, 135652]  0.098438\n",
      "10    [139252, 130412, 135652]  0.072741\n",
      "11           [4312482, 135652]  0.102501\n",
      "12            [102392, 135652]  0.100927\n",
      "13                      [5997]  0.220397\n",
      "14                [8892, 5997]  0.115950\n",
      "15        [102392, 8892, 5997]  0.077348\n",
      "16              [102392, 5997]  0.123820\n",
      "17              [139252, 5997]  0.114119\n",
      "18      [102392, 139252, 5997]  0.075488\n",
      "19        [8892, 139252, 5997]  0.072426\n",
      "20             [5267730, 5997]  0.117696\n",
      "21     [102392, 5267730, 5997]  0.078378\n",
      "22       [8892, 5267730, 5997]  0.075688\n",
      "23     [139252, 5267730, 5997]  0.082184\n",
      "24              [130412, 5997]  0.093458\n",
      "25                      [3461]  0.217021\n",
      "26                [8892, 3461]  0.113146\n",
      "27        [102392, 8892, 3461]  0.072226\n",
      "28                [5997, 3461]  0.112373\n",
      "29          [8892, 5997, 3461]  0.072168\n",
      "..                         ...       ...\n",
      "725                     [1650]  0.088394\n",
      "726                   [139952]  0.070137\n",
      "727                     [5050]  0.087964\n",
      "728                    [78552]  0.184542\n",
      "729            [102392, 78552]  0.100956\n",
      "730           [4312482, 78552]  0.089510\n",
      "731            [139252, 78552]  0.107795\n",
      "732      [8892, 139252, 78552]  0.072254\n",
      "733           [5267730, 78552]  0.100469\n",
      "734   [139252, 5267730, 78552]  0.075259\n",
      "735     [8892, 5267730, 78552]  0.070766\n",
      "736           [4316482, 78552]  0.071739\n",
      "737              [8892, 78552]  0.102358\n",
      "738            [130412, 78552]  0.088594\n",
      "739              [8792, 78552]  0.076890\n",
      "740            [102252, 78552]  0.079694\n",
      "741            [135652, 78552]  0.081755\n",
      "742                 [13372924]  0.090254\n",
      "743                     [2680]  0.086619\n",
      "744                     [4188]  0.076776\n",
      "745                 [23200609]  0.073971\n",
      "746                     [4340]  0.071739\n",
      "747                    [12872]  0.086877\n",
      "748                   [102312]  0.089452\n",
      "749                  [5912238]  0.072827\n",
      "750                 [21988886]  0.091370\n",
      "751                    [23432]  0.082613\n",
      "752                   [129152]  0.076804\n",
      "753                    [25732]  0.071310\n",
      "754                     [2572]  0.097179\n",
      "\n",
      "[755 rows x 2 columns]\n",
      "                                 rules_a             rules_b  confidence\n",
      "0    (4316382, 4316482, 130412, 5267730)            (139252)    0.919355\n",
      "1     (139252, 4316382, 4316482, 130412)           (5267730)    0.916262\n",
      "2             (134912, 4316482, 5267730)            (139252)    0.915323\n",
      "3             (4762754, 139252, 4316382)           (5267730)    0.912104\n",
      "4                     (4316442, 4316382)           (5267730)    0.903568\n",
      "5             (4316382, 4316482, 130412)            (139252)    0.901280\n",
      "6                     (4762754, 4316382)           (5267730)    0.898634\n",
      "7             (4316382, 4316482, 130412)           (5267730)    0.898248\n",
      "8                    (21986963, 4316382)           (5267730)    0.898168\n",
      "9             (139252, 4316382, 4316482)           (5267730)    0.897929\n",
      "10             (134912, 4316482, 130412)            (139252)    0.896866\n",
      "11               (8892, 4316482, 130412)            (139252)    0.896741\n",
      "12            (4316482, 130412, 5267730)            (139252)    0.893326\n",
      "13              (8892, 4316482, 5267730)            (139252)    0.892442\n",
      "14                              (140552)            (135652)    0.891789\n",
      "15                    (5267750, 4316382)           (5267730)    0.890117\n",
      "16            (4312482, 139252, 4316382)           (5267730)    0.888968\n",
      "17             (134912, 139252, 4316382)           (5267730)    0.888926\n",
      "18                    (21986963, 139252)           (5267730)    0.888276\n",
      "19               (8892, 139252, 4316382)           (5267730)    0.887521\n",
      "20                   (22718131, 4316382)           (5267730)    0.884801\n",
      "21             (134912, 4316382, 130412)           (5267730)    0.881893\n",
      "22             (139252, 4316382, 134932)           (5267730)    0.881165\n",
      "23           (4316382, 4316482, 5267730)            (139252)    0.880469\n",
      "24             (139252, 4316382, 130412)           (5267730)    0.879801\n",
      "25               (8892, 4316382, 130412)           (5267730)    0.876659\n",
      "26                    (4316382, 4316482)           (5267730)    0.870550\n",
      "27                     (134912, 4316482)            (139252)    0.869501\n",
      "28                    (4312482, 4316382)           (5267730)    0.868982\n",
      "29                     (102252, 4316482)            (139252)    0.867477\n",
      "..                                   ...                 ...         ...\n",
      "615                    (134912, 5267730)   (139252, 4316382)    0.608927\n",
      "616                   (22718131, 139252)           (5267750)    0.608906\n",
      "617                      (8892, 4316382)    (139252, 130412)    0.608715\n",
      "618                              (33512)            (102392)    0.608518\n",
      "619                           (22503880)          (22718131)    0.608497\n",
      "620                               (8792)              (8892)    0.607840\n",
      "621                      (4312482, 8892)   (139252, 5267730)    0.607759\n",
      "622                     (139252, 135652)              (8892)    0.607203\n",
      "623                    (139252, 5267730)           (4316482)    0.606983\n",
      "624                      (8892, 4316382)           (4316482)    0.606434\n",
      "625                    (4316482, 130412)   (139252, 4316382)    0.605752\n",
      "626                       (8792, 102252)              (8892)    0.605241\n",
      "627                               (6446)            (102392)    0.604482\n",
      "628                               (8992)           (5267730)    0.604356\n",
      "629                    (4316482, 130412)  (4316382, 5267730)    0.603714\n",
      "630                             (102792)            (139252)    0.603574\n",
      "631                            (4316382)              (8892)    0.603470\n",
      "632                         (8792, 8892)            (102392)    0.603260\n",
      "633                       (139252, 8892)           (4316382)    0.603246\n",
      "634                            (4312482)           (5267730)    0.603027\n",
      "635                               (6440)            (139252)    0.602521\n",
      "636           (139252, 4316482, 5267730)   (4316382, 130412)    0.602507\n",
      "637                    (4312482, 139252)           (5267750)    0.602022\n",
      "638                            (4762734)           (4312482)    0.601188\n",
      "639                            (4316442)           (4316382)    0.601043\n",
      "640                            (4316382)            (130412)    0.600716\n",
      "641                       (102392, 5997)              (5800)    0.600647\n",
      "642                              (78352)           (5267730)    0.600615\n",
      "643                    (130412, 5267730)            (134912)    0.600407\n",
      "644                               (8812)            (102392)    0.600040\n",
      "\n",
      "[645 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_list = list(training_data[\"value\"])\n",
    "frequent_itemsets = fpg.find_frequent_itemsets(data_list, minimum_support=0.07 * len(data_list), include_support=True)\n",
    "print(type(frequent_itemsets))  # print type\n",
    "result = []\n",
    "for itemset, support in frequent_itemsets:  # 将generator结果存入list\n",
    "    result.append((itemset, support / len(data_list)))\n",
    "\n",
    "result_patterns = [i[0] for i in result]\n",
    "result_support = [i[1] for i in result]\n",
    "patterns_df = pd.DataFrame({\"fluent_patterns\": result_patterns, \"support\": result_support})\n",
    "patterns = {}\n",
    "for i in result:\n",
    "    patterns[frozenset(sorted(i[0]))] = i[1]\n",
    "print(\"-------------挖掘频繁项集---------------\")\n",
    "print(patterns_df)\n",
    "\n",
    "def generate_rules(patterns, min_confidence):\n",
    "    patterns_group = group_patterns_by_length(patterns)\n",
    "    raw_rules = defaultdict(set)\n",
    "    for length, pattern_list in patterns_group.items():\n",
    "        if length == 1:\n",
    "            continue\n",
    "        for pattern, support in pattern_list:\n",
    "            item_list = list(pattern)\n",
    "            for window_size in range(1, length):\n",
    "                for i in range(0, length - window_size):\n",
    "                    for j in range(i + window_size, length):\n",
    "                        base_set = frozenset(item_list[i:j])\n",
    "                        predict_set = frozenset(pattern - base_set)\n",
    "                        confidence = support / patterns.get(base_set)\n",
    "                        if confidence > min_confidence:\n",
    "                            raw_rules[base_set].add((predict_set, confidence))\n",
    "\n",
    "                        base_set, predict_set = predict_set, base_set\n",
    "                        confidence = support / patterns.get(base_set)\n",
    "                        if confidence > min_confidence:\n",
    "                            raw_rules[base_set].add((predict_set, confidence))\n",
    "    return raw_rules\n",
    "\n",
    "def group_patterns_by_length(patterns):\n",
    "    result = defaultdict(list)\n",
    "    for pattern, support in patterns.items():\n",
    "        result[len(pattern)].append((pattern, support))\n",
    "    return result\n",
    "\n",
    "def transform(raw_rules):\n",
    "    result = list()\n",
    "    for base_set, predict_set_list in raw_rules.items():\n",
    "        for predict_set, confidence in predict_set_list:\n",
    "            result.append((base_set, predict_set, confidence))\n",
    "\n",
    "    return result\n",
    "raw_rules = generate_rules(patterns, 0.6)\n",
    "rules = transform(raw_rules)\n",
    "rules.sort(key=lambda x: x[2], reverse=True)\n",
    "rules_a = [i[0] for i in rules]\n",
    "rules_b = [i[1] for i in rules]\n",
    "confidence = [i[2] for i in rules]\n",
    "rules_df = pd.DataFrame({\"rules_a\": rules_a, \"rules_b\": rules_b, \"confidence\": confidence})\n",
    "print(rules_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import association_rules\n",
    "animation = pd.read_json(\"./test_data/bilibili_crawler_animation.json\", encoding=\"utf-8\")\n",
    "animation[\"score\"] = animation[\"score\"].fillna('%.1f' % animation[\"score\"].mean())\n",
    "animation[[\"follow\", \"play\"]] = animation[[\"follow\", \"play\"]].applymap(association_rules.trans)\n",
    "animation_feature = pd.read_json(\"./test_data/bilibili_crawler_animation_feature.json\",dtype={\"character_voice_list\": str})\n",
    "animation_feature[[\"tag_list\", \"character_voice_list\", \"character_staff_list\"]] = animation_feature[[\"tag_list\", \"character_voice_list\", \"character_staff_list\"]].applymap(json.loads)\n",
    "\n",
    "# #将关联规则的后项展开\n",
    "rules_df = association_rules.unfold_rules(rules_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_good_para(rules,animation, animation_feature,confidence=0.5,score=0.1,play=0.1,follow=0.1,voice=0.1,staff=0.1):\n",
    "    rules_weight = {\"confidence\": confidence, \"score\": score, \"play\": play, \"follow\": follow, \"voice\": voice, \"staff\": staff}\n",
    "    rules_df = association_rules.add_score(rules, rules_weight, animation, animation_feature)\n",
    "    rules_df.sort_values(by='score',inplace=True,ascending=False)\n",
    "    \n",
    "    new_rule = []\n",
    "    for index,row in rules_df.iterrows():\n",
    "        b=[]\n",
    "        for item in row[0]:\n",
    "            b.append(str(item))\n",
    "        new_rule.append([b,[str(row[1])]])\n",
    "    \n",
    "    print(rules_weight)\n",
    "    print('\\t000-100 : ',evaluate_association_rules(new_rule[:100],evaluate_data))\n",
    "    return new_rule\n",
    "#     print('\\t100-200 : ',evaluate_association_rules(new_rule[100:200],evaluate_data))\n",
    "#     print('\\t200-300 : ',evaluate_association_rules(new_rule[200:300],evaluate_data))\n",
    "#     print('\\tall_data: ',evaluate_association_rules(new_rule,evaluate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'confidence': 0.5, 'score': 0.1, 'play': 0.1, 'follow': 0.1, 'voice': 0.1, 'staff': 0.1}\n",
      "\t000-100 :  0.8473675485953\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"confidence\": 0.5, \n",
    "    \"score\": 0.1, \n",
    "    \"play\": 0.1, \n",
    "    \"follow\": 0.1, \n",
    "    \"voice\": 0.1, \n",
    "    \"staff\": 0.1\n",
    "}\n",
    "\n",
    "\n",
    "final_rule = find_good_para(rules_df,animation, animation_feature,**config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(rules,user_data):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        rules:推荐规则    格式：[[rules_a][rules_b]]\n",
    "        user_data:用户收藏信息  格式：Dataframe 包含value\n",
    "        \n",
    "    Returns:\n",
    "        推荐影片ID列表（10个以内）\n",
    "    \"\"\"\n",
    "    recommend_list = []\n",
    "    for rule_a,rule_b in rules:\n",
    "        rule_a_set = set(rule_a)\n",
    "        user_data_set = set(user_data.value) \n",
    "\n",
    "        if rule_a_set.issubset(user_data_set):\n",
    "            if rule_b[0] not in recommend_list: # rule_b都是只有一个影片，所以用rule_b[0]提取出来就行\n",
    "                recommend_list.append(rule_b[0])           \n",
    "    return recommend_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "db                                                       7\n",
       "key                                               23474560\n",
       "size                                                   368\n",
       "ttl                                                     -1\n",
       "type                                                   set\n",
       "value    [173, 184, 425, 472, 685, 687, 835, 1177, 1294...\n",
       "Name: 16634, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['135652',\n",
       " '102392',\n",
       " '139252',\n",
       " '5267730',\n",
       " '8892',\n",
       " '5800',\n",
       " '102252',\n",
       " '5997',\n",
       " '3461',\n",
       " '6446']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(final_rule,training_data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
